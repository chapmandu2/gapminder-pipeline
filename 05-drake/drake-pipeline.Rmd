---
title: "Drake Pipeline"
author: Phil Chapman
date: 2019-01-29
output: 
    html_document:
        number_sections: yes
        theme: cosmo
        highlight: tango
        toc: yes
        toc_depth: 3
        code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

In this analysis we use the drake package to define a pipeline to carry out the basic analyses of the gapminder data that we have done previously.

# Set up

## Load R libraries

```{r, message=FALSE}
library(dplyr)
library(ggplot2)
library(gapminder)
library(future)
library(drake)
library(clustermq)
```


# Drake pipeline

## Define functions

It is useful to define a few functions that we will use in the pipeline.  They can then be reused, unit tested etc.

### Function to fit linear model

This function fits a linear model to a data from containing the `lifeExp` and `year` columns.  A sleep call is added to simulate a long running task. 

```{r}
slow_lm <- function(df, sleep=0) {
  Sys.sleep(sleep)
  lm(lifeExp ~ year, df)
}
```

### Function to plot coefficient estimates

This function plots coefficient estimates from the `broom::tidy` function.

```{r}
plot_slopes <- function(df) {
  ggplot(df, aes(continent, estimate, color = continent)) +
    geom_violin() +
    geom_point(position = position_jitter(width=0.3)) +
    theme_bw()
}

```

### Function to calculate slope

This function generates a linear model from the gapminder data for a particular country and then extracts the slope into a data frame in a similar format to that generated by `broom::tidy`

```{r}
calculate_slope <- function(df, country, sleep) {
  
  dat <- df %>%
    dplyr::filter(country == !!country)
  
  mod <- slow_lm(dat, sleep = sleep)
  
  dat %>%
    distinct(continent, country) %>%
    mutate_all(as.character) %>%
    mutate(estimate=coef(mod)[['year']])

}

calculate_slope(gapminder, 'New Zealand', 0)

```

## Set up simple plan

Here we get up a very simple plan which is to load some data and then plot a graph:

```{r}
drake::clean(destroy=TRUE)

gm_pipeline_simple <- drake_plan(
  data_simple = gapminder::gapminder,
  plot_simple = ggplot(data_simple, aes(x=year, y=lifeExp, group=country, color=continent)) + 
    geom_line(alpha=0.3) + theme_bw()
)
```

Runing the plan generates two targets:

```{r}
make(gm_pipeline_simple)
```

We can then view the output of the pipeline:

```{r}
readd(plot_simple)
```

## Set up more complex plan

This example is the same analysis as was carried out previously - ie fit a linear model to data for each country and then plot the slope estimates by continent.

```{r}
drake::clean(destroy=TRUE)

gm_pipeline_complex <- drake_plan(
  data = gapminder::gapminder,
  many_models = data %>%
    group_by(continent, country) %>%
    tidyr::nest() %>%
    mutate(mod = purrr::map(data, slow_lm)),
  results = many_models %>%
    mutate(tidy_mod = purrr::map(mod, broom::tidy)) %>%
    dplyr::select(-data, -mod) %>%
    tidyr::unnest() %>%
    dplyr::filter(term == 'year'),
  plot = plot_slopes(results)
)

```

Run the plan:

```{r}
make(gm_pipeline_complex)
```

View output:

```{r}
readd(results)
readd(plot)
```

## Set up very complex plan

Rather than using the list-cols method of model fitting and coefficient extraction used earlier, here we fit a model for each country and then combine the results.  The benefit of this approach is that it is less memory intensive and can be more conventionally scaled across multiple machines.

```{r}
drake::clean(destroy=TRUE)

gm_countries <- gapminder %>% distinct(country) %>% 
  unlist() %>% unname() %>% as.character()

par_plan = drake_plan(
  data_par = gapminder,
  countries_par = unique(data_par$country) %>% as.character(),
  results_par = target(
    calculate_slope(df=data_par, country = country_val, sleep = 0),
    transform = map(country_val = !!gm_countries)
  ),
  results = target(
    bind_rows(results_par),
    transform = combine(results_par)
  ),
plot = plot_slopes(results),
  trace=TRUE
)
```

View the plan

```{r}
par_plan
```

Make the plan
```{r}
make(par_plan, verbose=0)
```

View the output
```{r}
readd(plot)
```

The same plot is generated as before.

# Parallisation of the pipeline

## Introduction

Drake includes interfaces to the future and clustermq packages for parallelisation, in addition to the default mode which is sequential computation.  These packages in turn allow pipelines to be run across common HPC schedulers such as SLURM and SGE.

## Sequential

Here we run the pipeline as before but time how long it takes to run:

```{r}
drake::clean()
pt <- proc.time()
make(par_plan, parallelism = "loop", verbose=0)
proc.time() - pt
```

## Future

We then run the pipeline using the future package in multicore mode with 4 processors.  Once again, since future imposes some overhead and the individual model fitting tasks are very fast, future performs more slowly that sequential mode.

```{r}
plan(multicore(workers=4))

drake::clean()
pt <- proc.time()
make(par_plan, parallelism = "future", jobs = 4, verbose=0)
proc.time() - pt
```

## Clustermq

The clustermq R package wraps the zeromq library which imposes much less parallisation overhead and uses persistent workers - ie a new process isn't started for each individual task.  It is quicker than future but still slower than sequential. 

```{r}
drake::clean()
pt <- proc.time()
options(clustermq.scheduler = "multicore")
make(par_plan, parallelism = "clustermq", verbose=0, jobs=4)
proc.time() - pt
```

# Conclusion

In this analaysis we have converted our original analysis into a pipeline which could then be broken up into tasks to be computed in parallel.  Although this has made things slower than in our original analysis, it does set a useful framework for computation as individual tasks become more CPU and memory intensive.  In general, future gives us the most flexibility but is slowest, whereas clustermq is faster but has fewer scheduler options.

# Session Info

```{r}
sessionInfo()
```
